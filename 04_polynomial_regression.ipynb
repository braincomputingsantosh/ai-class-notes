{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZSyQmNu0IsJ"
      },
      "outputs": [],
      "source": [
        "# Polynomial Regression: Complete Google Colab Example\n",
        "# This example demonstrates polynomial regression using a synthetic dataset\n",
        "# that exhibits a clear non-linear relationship\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"=== Polynomial Regression Demonstration ===\\n\")\n",
        "\n",
        "# Step 1: Generate synthetic dataset with non-linear relationship\n",
        "print(\"Step 1: Generating synthetic dataset...\")\n",
        "\n",
        "# Create a dataset representing \"Study Hours vs Test Score\" with diminishing returns\n",
        "n_samples = 100\n",
        "X = np.linspace(0, 10, n_samples).reshape(-1, 1)  # Study hours (0-10)\n",
        "\n",
        "# True relationship: quadratic with some noise\n",
        "# Score = 20 + 15*hours - 0.8*hours^2 + noise\n",
        "# This creates an inverted U-shape (diminishing returns)\n",
        "true_function = 20 + 15*X.ravel() - 0.8*X.ravel()**2\n",
        "noise = np.random.normal(0, 3, n_samples)  # Add realistic noise\n",
        "y = true_function + noise\n",
        "\n",
        "# Ensure scores are realistic (0-100 range)\n",
        "y = np.clip(y, 0, 100)\n",
        "\n",
        "print(f\"Dataset created: {n_samples} samples\")\n",
        "print(f\"X range: {X.min():.1f} to {X.max():.1f} hours\")\n",
        "print(f\"y range: {y.min():.1f} to {y.max():.1f} points\\n\")\n",
        "\n",
        "# Step 2: Create and compare different polynomial degrees\n",
        "print(\"Step 2: Training polynomial regression models...\")\n",
        "\n",
        "degrees = [1, 2, 3, 4]  # Test different polynomial degrees\n",
        "models = {}\n",
        "predictions = {}\n",
        "r2_scores = {}\n",
        "\n",
        "# Train models for each degree\n",
        "for degree in degrees:\n",
        "    print(f\"Training degree {degree} polynomial...\")\n",
        "\n",
        "    # Create polynomial features\n",
        "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "\n",
        "    # Create pipeline: Polynomial Features -> Linear Regression\n",
        "    model = Pipeline([\n",
        "        ('poly_features', poly_features),\n",
        "        ('linear_regression', LinearRegression())\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # Calculate R-squared score\n",
        "    r2 = r2_score(y, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    models[degree] = model\n",
        "    predictions[degree] = y_pred\n",
        "    r2_scores[degree] = r2\n",
        "\n",
        "    print(f\"  R-squared score: {r2:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 3: Display model performance comparison\n",
        "print(\"Step 3: Model Performance Comparison\")\n",
        "print(\"-\" * 40)\n",
        "for degree in degrees:\n",
        "    mse = mean_squared_error(y, predictions[degree])\n",
        "    print(f\"Degree {degree}: R² = {r2_scores[degree]:.4f}, MSE = {mse:.2f}\")\n",
        "\n",
        "# Find best model based on R-squared\n",
        "best_degree = max(r2_scores, key=r2_scores.get)\n",
        "print(f\"\\nBest performing model: Degree {best_degree} (R² = {r2_scores[best_degree]:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 4: Detailed analysis of the best model\n",
        "print(\"Step 4: Detailed Analysis of Best Model\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "best_model = models[best_degree]\n",
        "best_poly_features = best_model.named_steps['poly_features']\n",
        "best_linear_reg = best_model.named_steps['linear_regression']\n",
        "\n",
        "# Get feature names and coefficients\n",
        "feature_names = best_poly_features.get_feature_names_out(['hours'])\n",
        "coefficients = best_linear_reg.coef_\n",
        "intercept = best_linear_reg.intercept_\n",
        "\n",
        "print(f\"Polynomial Equation (degree {best_degree}):\")\n",
        "print(f\"Test Score = {intercept:.2f}\", end=\"\")\n",
        "for i, (name, coef) in enumerate(zip(feature_names, coefficients)):\n",
        "    sign = \"+\" if coef >= 0 else \"-\"\n",
        "    print(f\" {sign} {abs(coef):.2f}*{name}\", end=\"\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Step 5: Create comprehensive visualization\n",
        "print(\"Step 5: Creating visualization...\")\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Polynomial Regression Analysis: Study Hours vs Test Scores', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Colors for different degrees\n",
        "colors = ['red', 'green', 'blue', 'orange']\n",
        "\n",
        "# Plot 1: All polynomial fits\n",
        "ax1.scatter(X, y, alpha=0.6, color='black', s=30, label='Data points')\n",
        "for i, degree in enumerate(degrees):\n",
        "    ax1.plot(X, predictions[degree], color=colors[i], linewidth=2,\n",
        "             label=f'Degree {degree} (R²={r2_scores[degree]:.3f})')\n",
        "ax1.set_xlabel('Study Hours')\n",
        "ax1.set_ylabel('Test Score')\n",
        "ax1.set_title('Comparison of Different Polynomial Degrees')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Focus on best model\n",
        "ax2.scatter(X, y, alpha=0.6, color='black', s=30, label='Actual data')\n",
        "ax2.plot(X, predictions[best_degree], color='red', linewidth=3,\n",
        "         label=f'Best fit (Degree {best_degree})')\n",
        "ax2.set_xlabel('Study Hours')\n",
        "ax2.set_ylabel('Test Score')\n",
        "ax2.set_title(f'Best Model: Degree {best_degree} Polynomial')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Residuals analysis\n",
        "residuals = y - predictions[best_degree]\n",
        "ax3.scatter(predictions[best_degree], residuals, alpha=0.6, color='blue', s=30)\n",
        "ax3.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
        "ax3.set_xlabel('Predicted Test Score')\n",
        "ax3.set_ylabel('Residuals')\n",
        "ax3.set_title('Residuals Plot (Best Model)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: R-squared comparison\n",
        "ax4.bar(range(len(degrees)), [r2_scores[d] for d in degrees],\n",
        "        color=colors, alpha=0.7)\n",
        "ax4.set_xlabel('Polynomial Degree')\n",
        "ax4.set_ylabel('R-squared Score')\n",
        "ax4.set_title('Model Performance Comparison')\n",
        "ax4.set_xticks(range(len(degrees)))\n",
        "ax4.set_xticklabels([f'Degree {d}' for d in degrees])\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, degree in enumerate(degrees):\n",
        "    ax4.text(i, r2_scores[degree] + 0.01, f'{r2_scores[degree]:.3f}',\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 6: Making predictions with the best model\n",
        "print(\"Step 6: Making Predictions\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Example predictions for new data points\n",
        "new_hours = np.array([[2], [5], [8]])\n",
        "new_predictions = best_model.predict(new_hours)\n",
        "\n",
        "print(\"Predictions for new study hours:\")\n",
        "for hrs, pred in zip(new_hours.flatten(), new_predictions):\n",
        "    print(f\"  {hrs} hours/week → {pred:.1f} points\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 7: Key insights and interpretation\n",
        "print(\"Step 7: Key Insights\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "print(\"1. RELATIONSHIP PATTERN:\")\n",
        "if best_degree == 2:\n",
        "    print(\"   • Quadratic relationship detected (inverted U-shape)\")\n",
        "    print(\"   • Shows diminishing returns pattern\")\n",
        "    print(\"   • Optimal study time exists where performance peaks\")\n",
        "elif best_degree == 3:\n",
        "    print(\"   • Cubic relationship detected (S-shape)\")\n",
        "    print(\"   • More complex pattern with multiple inflection points\")\n",
        "else:\n",
        "    print(f\"   • Degree {best_degree} polynomial provides best fit\")\n",
        "\n",
        "print(\"\\n2. PRACTICAL IMPLICATIONS:\")\n",
        "print(\"   • Initial study hours show strong positive returns\")\n",
        "print(\"   • Additional hours beyond optimal point show diminishing returns\")\n",
        "print(\"   • Over-studying might lead to decreased performance\")\n",
        "\n",
        "print(\"\\n3. MODEL QUALITY:\")\n",
        "print(f\"   • Best model explains {r2_scores[best_degree]*100:.1f}% of variance\")\n",
        "print(f\"   • Residuals appear randomly distributed (good sign)\")\n",
        "\n",
        "# Find optimal study hours (if quadratic)\n",
        "if best_degree == 2:\n",
        "    optimal_hours = -coefficients[0] / (2 * coefficients[1])\n",
        "    if 0 <= optimal_hours <= 10:  # Within our data range\n",
        "        optimal_score = best_model.predict([[optimal_hours]])[0]\n",
        "        print(f\"   • Optimal study time: ~{optimal_hours:.1f} hours (score: {optimal_score:.1f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Analysis Complete! 🎉\")\n",
        "print(\"\\nKey Takeaways:\")\n",
        "print(\"• Polynomial regression successfully captured non-linear relationship\")\n",
        "print(\"• Higher degrees don't always mean better models (risk of overfitting)\")\n",
        "print(\"• Visual inspection and residual analysis are crucial for model validation\")\n",
        "print(\"• The model provides actionable insights about optimal study strategies\")"
      ]
    }
  ]
}
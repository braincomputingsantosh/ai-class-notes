{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZSyQmNu0IsJ"
      },
      "outputs": [],
      "source": [
        "# Polynomial Regression: Complete Google Colab Example\n",
        "# This example demonstrates polynomial regression using a synthetic dataset\n",
        "# that exhibits a clear non-linear relationship\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"=== Polynomial Regression Demonstration ===\\n\")\n",
        "\n",
        "# Step 1: Generate synthetic dataset with non-linear relationship\n",
        "print(\"Step 1: Generating synthetic dataset...\")\n",
        "\n",
        "# Create a dataset representing \"Study Hours vs Test Score\" with diminishing returns\n",
        "n_samples = 100\n",
        "X = np.linspace(0, 10, n_samples).reshape(-1, 1)  # Study hours (0-10)\n",
        "\n",
        "# True relationship: quadratic with some noise\n",
        "# Score = 20 + 15*hours - 0.8*hours^2 + noise\n",
        "# This creates an inverted U-shape (diminishing returns)\n",
        "true_function = 20 + 15*X.ravel() - 0.8*X.ravel()**2\n",
        "noise = np.random.normal(0, 3, n_samples)  # Add realistic noise\n",
        "y = true_function + noise\n",
        "\n",
        "# Ensure scores are realistic (0-100 range)\n",
        "y = np.clip(y, 0, 100)\n",
        "\n",
        "print(f\"Dataset created: {n_samples} samples\")\n",
        "print(f\"X range: {X.min():.1f} to {X.max():.1f} hours\")\n",
        "print(f\"y range: {y.min():.1f} to {y.max():.1f} points\\n\")\n",
        "\n",
        "# Step 2: Create and compare different polynomial degrees\n",
        "print(\"Step 2: Training polynomial regression models...\")\n",
        "\n",
        "degrees = [1, 2, 3, 4]  # Test different polynomial degrees\n",
        "models = {}\n",
        "predictions = {}\n",
        "r2_scores = {}\n",
        "\n",
        "# Train models for each degree\n",
        "for degree in degrees:\n",
        "    print(f\"Training degree {degree} polynomial...\")\n",
        "\n",
        "    # Create polynomial features\n",
        "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "\n",
        "    # Create pipeline: Polynomial Features -> Linear Regression\n",
        "    model = Pipeline([\n",
        "        ('poly_features', poly_features),\n",
        "        ('linear_regression', LinearRegression())\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # Calculate R-squared score\n",
        "    r2 = r2_score(y, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    models[degree] = model\n",
        "    predictions[degree] = y_pred\n",
        "    r2_scores[degree] = r2\n",
        "\n",
        "    print(f\"  R-squared score: {r2:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 3: Display model performance comparison\n",
        "print(\"Step 3: Model Performance Comparison\")\n",
        "print(\"-\" * 40)\n",
        "for degree in degrees:\n",
        "    mse = mean_squared_error(y, predictions[degree])\n",
        "    print(f\"Degree {degree}: RÂ² = {r2_scores[degree]:.4f}, MSE = {mse:.2f}\")\n",
        "\n",
        "# Find best model based on R-squared\n",
        "best_degree = max(r2_scores, key=r2_scores.get)\n",
        "print(f\"\\nBest performing model: Degree {best_degree} (RÂ² = {r2_scores[best_degree]:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 4: Detailed analysis of the best model\n",
        "print(\"Step 4: Detailed Analysis of Best Model\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "best_model = models[best_degree]\n",
        "best_poly_features = best_model.named_steps['poly_features']\n",
        "best_linear_reg = best_model.named_steps['linear_regression']\n",
        "\n",
        "# Get feature names and coefficients\n",
        "feature_names = best_poly_features.get_feature_names_out(['hours'])\n",
        "coefficients = best_linear_reg.coef_\n",
        "intercept = best_linear_reg.intercept_\n",
        "\n",
        "print(f\"Polynomial Equation (degree {best_degree}):\")\n",
        "print(f\"Test Score = {intercept:.2f}\", end=\"\")\n",
        "for i, (name, coef) in enumerate(zip(feature_names, coefficients)):\n",
        "    sign = \"+\" if coef >= 0 else \"-\"\n",
        "    print(f\" {sign} {abs(coef):.2f}*{name}\", end=\"\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Step 5: Create comprehensive visualization\n",
        "print(\"Step 5: Creating visualization...\")\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Polynomial Regression Analysis: Study Hours vs Test Scores', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Colors for different degrees\n",
        "colors = ['red', 'green', 'blue', 'orange']\n",
        "\n",
        "# Plot 1: All polynomial fits\n",
        "ax1.scatter(X, y, alpha=0.6, color='black', s=30, label='Data points')\n",
        "for i, degree in enumerate(degrees):\n",
        "    ax1.plot(X, predictions[degree], color=colors[i], linewidth=2,\n",
        "             label=f'Degree {degree} (RÂ²={r2_scores[degree]:.3f})')\n",
        "ax1.set_xlabel('Study Hours')\n",
        "ax1.set_ylabel('Test Score')\n",
        "ax1.set_title('Comparison of Different Polynomial Degrees')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Focus on best model\n",
        "ax2.scatter(X, y, alpha=0.6, color='black', s=30, label='Actual data')\n",
        "ax2.plot(X, predictions[best_degree], color='red', linewidth=3,\n",
        "         label=f'Best fit (Degree {best_degree})')\n",
        "ax2.set_xlabel('Study Hours')\n",
        "ax2.set_ylabel('Test Score')\n",
        "ax2.set_title(f'Best Model: Degree {best_degree} Polynomial')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Residuals analysis\n",
        "residuals = y - predictions[best_degree]\n",
        "ax3.scatter(predictions[best_degree], residuals, alpha=0.6, color='blue', s=30)\n",
        "ax3.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
        "ax3.set_xlabel('Predicted Test Score')\n",
        "ax3.set_ylabel('Residuals')\n",
        "ax3.set_title('Residuals Plot (Best Model)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: R-squared comparison\n",
        "ax4.bar(range(len(degrees)), [r2_scores[d] for d in degrees],\n",
        "        color=colors, alpha=0.7)\n",
        "ax4.set_xlabel('Polynomial Degree')\n",
        "ax4.set_ylabel('R-squared Score')\n",
        "ax4.set_title('Model Performance Comparison')\n",
        "ax4.set_xticks(range(len(degrees)))\n",
        "ax4.set_xticklabels([f'Degree {d}' for d in degrees])\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, degree in enumerate(degrees):\n",
        "    ax4.text(i, r2_scores[degree] + 0.01, f'{r2_scores[degree]:.3f}',\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 6: Making predictions with the best model\n",
        "print(\"Step 6: Making Predictions\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Example predictions for new data points\n",
        "new_hours = np.array([[2], [5], [8]])\n",
        "new_predictions = best_model.predict(new_hours)\n",
        "\n",
        "print(\"Predictions for new study hours:\")\n",
        "for hrs, pred in zip(new_hours.flatten(), new_predictions):\n",
        "    print(f\"  {hrs} hours/week â†’ {pred:.1f} points\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Step 7: Key insights and interpretation\n",
        "print(\"Step 7: Key Insights\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "print(\"1. RELATIONSHIP PATTERN:\")\n",
        "if best_degree == 2:\n",
        "    print(\"   â€¢ Quadratic relationship detected (inverted U-shape)\")\n",
        "    print(\"   â€¢ Shows diminishing returns pattern\")\n",
        "    print(\"   â€¢ Optimal study time exists where performance peaks\")\n",
        "elif best_degree == 3:\n",
        "    print(\"   â€¢ Cubic relationship detected (S-shape)\")\n",
        "    print(\"   â€¢ More complex pattern with multiple inflection points\")\n",
        "else:\n",
        "    print(f\"   â€¢ Degree {best_degree} polynomial provides best fit\")\n",
        "\n",
        "print(\"\\n2. PRACTICAL IMPLICATIONS:\")\n",
        "print(\"   â€¢ Initial study hours show strong positive returns\")\n",
        "print(\"   â€¢ Additional hours beyond optimal point show diminishing returns\")\n",
        "print(\"   â€¢ Over-studying might lead to decreased performance\")\n",
        "\n",
        "print(\"\\n3. MODEL QUALITY:\")\n",
        "print(f\"   â€¢ Best model explains {r2_scores[best_degree]*100:.1f}% of variance\")\n",
        "print(f\"   â€¢ Residuals appear randomly distributed (good sign)\")\n",
        "\n",
        "# Find optimal study hours (if quadratic)\n",
        "if best_degree == 2:\n",
        "    optimal_hours = -coefficients[0] / (2 * coefficients[1])\n",
        "    if 0 <= optimal_hours <= 10:  # Within our data range\n",
        "        optimal_score = best_model.predict([[optimal_hours]])[0]\n",
        "        print(f\"   â€¢ Optimal study time: ~{optimal_hours:.1f} hours (score: {optimal_score:.1f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Analysis Complete! ðŸŽ‰\")\n",
        "print(\"\\nKey Takeaways:\")\n",
        "print(\"â€¢ Polynomial regression successfully captured non-linear relationship\")\n",
        "print(\"â€¢ Higher degrees don't always mean better models (risk of overfitting)\")\n",
        "print(\"â€¢ Visual inspection and residual analysis are crucial for model validation\")\n",
        "print(\"â€¢ The model provides actionable insights about optimal study strategies\")"
      ]
    }
  ]
}